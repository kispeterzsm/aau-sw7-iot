# Base Image with GPU support
FROM nvidia/cuda:12.1.1-devel-ubuntu22.04
ENV DEBIAN_FRONTEND=noninteractive
RUN apt-get update && apt-get install -y python3-pip git && \
    rm -rf /var/lib/apt/lists/*
RUN ln -sf /usr/bin/python3 /usr/bin/python
WORKDIR /app

# Split pip installations into separate layers
RUN pip install --upgrade pip
RUN pip install torch torchvision torchaudio
RUN pip install transformers accelerate huggingface_hub

# Setup Environment
ARG HF_TOKEN
ENV HF_TOKEN=$HF_TOKEN
ENV MODEL_NAME="Qwen/Qwen3-4B-Instruct-2507"
ENV HF_HOME="/app/model_cache"
RUN huggingface-cli login --token $HF_TOKEN

# Download each model file in separate layers
RUN huggingface-cli download $MODEL_NAME config.json --cache-dir $HF_HOME
RUN huggingface-cli download $MODEL_NAME tokenizer.json --cache-dir $HF_HOME
RUN huggingface-cli download $MODEL_NAME tokenizer_config.json --cache-dir $HF_HOME
RUN huggingface-cli download $MODEL_NAME generation_config.json --cache-dir $HF_HOME
RUN huggingface-cli download $MODEL_NAME model-00001-of-00003.safetensors --cache-dir $HF_HOME
RUN huggingface-cli download $MODEL_NAME model-00002-of-00003.safetensors --cache-dir $HF_HOME
RUN huggingface-cli download $MODEL_NAME model-00003-of-00003.safetensors --cache-dir $HF_HOME
# Download any remaining files
RUN huggingface-cli download $MODEL_NAME --cache-dir $HF_HOME